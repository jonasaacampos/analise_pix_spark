{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpXPtmLKKxnk"
   },
   "source": [
    "## 1 - Preparação do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Preparação do ambiente</summary>\n",
    "\n",
    "### Preparação do ambiente\n",
    "\n",
    "#### IDEs utilizada\n",
    "\n",
    " - VSCode\n",
    "\n",
    "#### Criar ambiente virtual\n",
    "\n",
    "- Command Pallet (ctrl + shift+ p)\n",
    "- Python: Create Environment > Venv > Python Version (3.12)'\n",
    "\n",
    "#### Ativar .venv\n",
    "\n",
    "In VsCode terminal, alterar a política de execução de scripts para ativar o ambiente virtual.\n",
    "\n",
    "```bash\n",
    "Set-ExecutionPolicy Unrestricted -Scope Process\n",
    "\n",
    "# ativar ambiente virtual\n",
    ".\\.venv\\Scripts\\activate\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFBKW-UUAMOo"
   },
   "source": [
    "## 2 - Data Undesrtanting\n",
    "\n",
    "Primeiramente, devemos entender tudo sobre a fonte dos dados\n",
    "- Como o dado chega até nós?\n",
    "- Qual formato virá? \n",
    "- Aonde o processamento será executado (AWS EMR, Cluster On-Premise)? \n",
    "- De quanto em quanto tempo eu preciso gerar esse relatório (mensal, diário, near-real time)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados foram compartilhados via `*.json`. Saber como os dados serão ingeridos são de vital importância para delimitar a forma como lidaremos com nosso projeto. Análises em tempo real (streaming) são diferentes de análises em lotes (bacthes). Análises pontuais como esta também adotam uma estratégia diferentes das que requerem análises periódicas.\n",
    "\n",
    "### Data Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id_transacao\": inteiro,\n",
    "  \"valor\": texto,\n",
    "  \"remetente\": {\n",
    "      \"nome\": texto,\n",
    "      \"banco\": texto,\n",
    "      \"tipo\": texto\n",
    "  }, \n",
    "  \"destinatario\": {\n",
    "      \"nome\": texto, \n",
    "      \"banco\":texto,\n",
    "      \"tipo\": texto\n",
    "  },        \n",
    "  \"categoria\": texto,\n",
    "  \"transaction_date\":texto,\n",
    "  \"chave_pix\":texto,\n",
    "  \"fraude\":inteiro,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPvcwRICAPod"
   },
   "source": [
    "## 3 - Preparação dos Dados\n",
    "\n",
    "Agora é hora de começar a preparar os dados de acordo com as necessidades do escopo de trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando bibliotecas e componentes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyspark\n",
    "#%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, date_format, length, max, min, avg, format_number, count, lit, floor, udf, round\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções personalizadas para apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para inicializar o spark\n",
    "def spark_initialize_session(app_name = 'My Analysis'):\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .config('spark.ui.port', '4050')\n",
    "        .appName(app_name)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    return spark\n",
    "\n",
    "\n",
    "# função para retornar a quantidade de linhas e colunas de um dataframe spark\n",
    "def spark_show_info_df(df):\n",
    "    df_lines = df.count()\n",
    "    df_columns = len(df.columns)\n",
    "    print(f'Dados do dataframe atual\\nLinhas: {df_lines:,} | Colunas: {df_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = f'data{os.sep}raw{os.sep}case_final.json'\n",
    "spark = spark_initialize_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**não usar o json formatado, isso causa lentidão e erros no algoritmo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>json schema anotations</summary>\n",
    "\n",
    "### Data Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id_transacao\": inteiro,\n",
    "  \"valor\": texto,\n",
    "  \"remetente\": {\n",
    "      \"nome\": texto,\n",
    "      \"banco\": texto,\n",
    "      \"tipo\": texto\n",
    "  }, \n",
    "  \"destinatario\": {\n",
    "      \"nome\": texto, \n",
    "      \"banco\":texto,\n",
    "      \"tipo\": texto\n",
    "  },        \n",
    "  \"categoria\": texto,\n",
    "  \"transaction_date\":texto,\n",
    "  \"chave_pix\":texto,\n",
    "  \"fraude\":inteiro,\n",
    "}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do data schema\n",
    "# amostra dos dados\n",
    "# { \"id_transacao\": 100999, \"valor\": 7058.09, \"remetente\": { \"nome\": \"Jonathan Gonsalves\", \"banco\": \"BTG\", \"tipo\": \"PF\" }, \"destinatario\": { \"nome\": \"Lais Nascimento\", \"banco\": \"Nubank\", \"tipo\": \"PF\" }, \"chave_pix\": \"aleatoria\", \"categoria\": \"vestuario\", \"transaction_date\": \"2022-02-25 09:31:47\", \"fraude\": 0 }\n",
    "\n",
    "data_schema_pix_remetente_destinatario = StructType([\n",
    "    StructField('nome', StringType()),\n",
    "    StructField('banco', StringType()),\n",
    "    StructField('tipo', StringType())\n",
    "    ])\n",
    "\n",
    "data_schema_pix = StructType([\n",
    "    StructField('id_transacao', IntegerType()),\n",
    "    StructField('valor', DoubleType()),\n",
    "    StructField('remetente', data_schema_pix_remetente_destinatario),   \n",
    "    StructField('destinatario', data_schema_pix_remetente_destinatario),\n",
    "    StructField('categoria', StringType()),\n",
    "    StructField('transaction_date', StringType()),\n",
    "    StructField('chave_pix', StringType(), True),\n",
    "    StructField('fraude', IntegerType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = f'data{os.sep}raw{os.sep}case_final.json'\n",
    "spark = spark_initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"transaction_date\": \"2022-02-25 09:31:47\"\n",
    "df = spark.read.json(df_path, \n",
    "                     schema=data_schema_pix, \n",
    "                     timestampFormat='yyyy-MM-dd HH:mm:ss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transacao: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- remetente: struct (nullable = true)\n",
      " |    |-- nome: string (nullable = true)\n",
      " |    |-- banco: string (nullable = true)\n",
      " |    |-- tipo: string (nullable = true)\n",
      " |-- destinatario: struct (nullable = true)\n",
      " |    |-- nome: string (nullable = true)\n",
      " |    |-- banco: string (nullable = true)\n",
      " |    |-- tipo: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- chave_pix: string (nullable = true)\n",
      " |-- fraude: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verificar tipo dos dados\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+--------------------+--------------------+-------------+-------------------+---------+------+\n",
      "|id_transacao|             valor|           remetente|        destinatario|    categoria|   transaction_date|chave_pix|fraude|\n",
      "+------------+------------------+--------------------+--------------------+-------------+-------------------+---------+------+\n",
      "|        1000|            588.08|{Jonathan Gonsalv...|{Calebe Melo, Cai...|       outros|2021-07-16 05:00:55|aleatoria|     0|\n",
      "|        1001|           80682.5|{Jonathan Gonsalv...|{Davi Lucas Perei...|transferencia|2022-04-20 12:34:01|  celular|     1|\n",
      "|        1002|             549.9|{Jonathan Gonsalv...|{Sabrina Castro, ...|        lazer|2022-07-10 16:51:34|      cpf|     0|\n",
      "|        1003|             90.83|{Jonathan Gonsalv...|{Francisco da Con...|   transporte|2022-10-20 10:57:36|aleatoria|     0|\n",
      "|        1004|13272.619999999999|{Jonathan Gonsalv...|{Isabelly Ferreir...|transferencia|2021-04-06 20:26:51|    email|     0|\n",
      "+------------+------------------+--------------------+--------------------+-------------+-------------------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualiar os dados no dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*precisamos remover as estruturas aninhadas que estão nas colunas remetente e destinatário*\n",
    "\n",
    "Para que cada coluna tenha apenas um tipo de dado, precisamos fazer o achatamento dos nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flatten = df.withColumns({\n",
    "    'remetente_nome': col('remetente').getField('nome'),\n",
    "    'remetente_banco': col('remetente').getField('banco'),\n",
    "    'remetente_tipo': col('remetente').getField('tipo'),\n",
    "\n",
    "    'destinatario_nome': col('destinatario').getField('nome'),\n",
    "    'destinatario_banco': col('destinatario').getField('banco'),\n",
    "    'destinatario_tipo': col('destinatario').getField('tipo'),\n",
    "    }).drop('remetente', 'destinatario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transacao: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- chave_pix: string (nullable = true)\n",
      " |-- fraude: integer (nullable = true)\n",
      " |-- remetente_nome: string (nullable = true)\n",
      " |-- remetente_banco: string (nullable = true)\n",
      " |-- remetente_tipo: string (nullable = true)\n",
      " |-- destinatario_nome: string (nullable = true)\n",
      " |-- destinatario_banco: string (nullable = true)\n",
      " |-- destinatario_tipo: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_flatten.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+\n",
      "|id_transacao|             valor|    categoria|   transaction_date|chave_pix|fraude|    remetente_nome|remetente_banco|remetente_tipo|   destinatario_nome|destinatario_banco|destinatario_tipo|\n",
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+\n",
      "|        1000|            588.08|       outros|2021-07-16 05:00:55|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|         Calebe Melo|             Caixa|               PF|\n",
      "|        1001|           80682.5|transferencia|2022-04-20 12:34:01|  celular|     1|Jonathan Gonsalves|            BTG|            PF|  Davi Lucas Pereira|             Caixa|               PJ|\n",
      "|        1002|             549.9|        lazer|2022-07-10 16:51:34|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|      Sabrina Castro|            Nubank|               PF|\n",
      "|        1003|             90.83|   transporte|2022-10-20 10:57:36|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|Francisco da Conc...|            Nubank|               PJ|\n",
      "|        1004|13272.619999999999|transferencia|2021-04-06 20:26:51|    email|     0|Jonathan Gonsalves|            BTG|            PF|   Isabelly Ferreira|               BTG|               PJ|\n",
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_flatten.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando a visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados do dataframe atual\n",
      "Linhas: 100,000 | Colunas: 12\n"
     ]
    }
   ],
   "source": [
    "spark_show_info_df(df_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "|id_transacao_max_lenght|valor_max_lenght|categoria_max_lenght|transaction_date_max_lenght|chave_pix_max_lenght|fraude_max_lenght|remetente_nome_max_lenght|remetente_banco_max_lenght|remetente_tipo_max_lenght|destinatario_nome_max_lenght|destinatario_banco_max_lenght|destinatario_tipo_max_lenght|\n",
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "|                      6|              18|                  13|                         19|                   9|                1|                       18|                         3|                        2|                          33|                            8|                           2|\n",
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "|id_transacao_min_lenght|valor_min_lenght|categoria_min_lenght|transaction_date_min_lenght|chave_pix_min_lenght|fraude_min_lenght|remetente_nome_min_lenght|remetente_banco_min_lenght|remetente_tipo_min_lenght|destinatario_nome_min_lenght|destinatario_banco_min_lenght|destinatario_tipo_min_lenght|\n",
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "|                      4|               3|                   5|                         19|                   3|                1|                       18|                         3|                        2|                           8|                            2|                           2|\n",
      "+-----------------------+----------------+--------------------+---------------------------+--------------------+-----------------+-------------------------+--------------------------+-------------------------+----------------------------+-----------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# mostra a quantidade máxima e mínima de caracteres de cada coluna\n",
    "df_flatten.select([max(length(col(c))).alias(c + '_max_lenght') for c in df_flatten.columns]).show()\n",
    "df_flatten.select([min(length(col(c))).alias(c + '_min_lenght') for c in df_flatten.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste para visualização de todas as colunas\n",
    "# o padrão é 20, o maior valor possível é 100\n",
    "# o valor 33 é o suficiente para visualizar todas as colunas com base no nosso dataframe.destinatario_nome_max_lenght\n",
    "spark.conf.set('spark.sql.debug.maxToStringFields', 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumarização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:23:19 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------+-------------------+---------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|summary|     id_transacao|             valor|  categoria|   transaction_date|chave_pix|            fraude|    remetente_nome|remetente_banco|remetente_tipo|destinatario_nome|destinatario_banco|destinatario_tipo|\n",
      "+-------+-----------------+------------------+-----------+-------------------+---------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|  count|           100000|            100000|     100000|             100000|   100000|            100000|            100000|         100000|        100000|           100000|            100000|           100000|\n",
      "|   mean|          50999.5|10303.358732200059|       NULL|               NULL|     NULL|           0.15367|              NULL|           NULL|          NULL|             NULL|              NULL|             NULL|\n",
      "| stddev|28867.65779668774| 20874.99768875586|       NULL|               NULL|     NULL|0.3606339302787737|              NULL|           NULL|          NULL|             NULL|              NULL|             NULL|\n",
      "|    min|             1000|               0.0|alimentacao|2021-01-14 15:37:45|aleatoria|                 0|Jonathan Gonsalves|            BTG|            PF|   Agatha Almeida|               BTG|               PF|\n",
      "|    max|           100999|          89996.33|  vestuario|2023-01-15 02:51:10|    email|                 1|Jonathan Gonsalves|            BTG|            PF|   Yuri das Neves|                XP|               PJ|\n",
      "+-------+-----------------+------------------+-----------+-------------------+---------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flatten.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Os maiores valores foram\n",
    "\n",
    "  - O pix de maior valor foi de R$89.996,33\n",
    "  - A categoria preponderante é **vestuário**\n",
    "  - A última transação ocorreu em *2023-01-15 02:51:10*\n",
    "  - A chave pix mais utilizada foram as registradas com o email\n",
    "  - O remetente que mais fez transações foi *Jonathan Gonsalves*\n",
    "  - O banco que mais fez transações foi o *BTG*\n",
    "  - O banco que mais recebeu transações foi o XP\n",
    "  - Os clientes Pessoa Física foram os que mais fizeram transações pix\n",
    "  - Os clientes Pessoa Jurídica são os que mais receberam transações pix\n",
    "  - O cliente que mais recebeu Transações foi *Yuri das Neves*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Os menores valores foram\n",
    "\n",
    "  - O pix de menor valor foi de R$0.00\n",
    "  - A categoria menos frequente foi **alimentação**\n",
    "  - A primeira transação ocorreu em *2021-01-14 15:37:45*\n",
    "  - A chave pix menor utilizada foram as chaves aleatórias\n",
    "  - O remetente que menos fez transações foi *Jonathan Gonsalves*\n",
    "  - O banco que menos fez transações foi o *BTG*\n",
    "  - O banco que menos recebeu transações foi o BTG\n",
    "  - Os clientes Pessoa Física foram os que menos fizeram transações pix\n",
    "  - Os clientes Pessoa Física são os que menos receberam transações pix\n",
    "  - O cliente que menos recebeu Transações foi *Yuri das Neves*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnOJ5pwHARTD"
   },
   "source": [
    "## 4 - Modelagem\n",
    "\n",
    "- Para qual banco esse cliente mais transfere?\n",
    "- Qual é a média de transferências por período que esse cliente faz?\n",
    "- Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
    "- Para o que esse cliente mais usa as transferências?\n",
    "- Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|destinatario_banco|count|\n",
      "+------------------+-----+\n",
      "|                XP|14401|\n",
      "|               BTG|14390|\n",
      "|            Nubank|14297|\n",
      "|              Itau|14281|\n",
      "|             Caixa|14240|\n",
      "|                C6|14204|\n",
      "|          Bradesco|14187|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Para qual banco foram feitas mais transações?\n",
    "df_flatten.groupBy('destinatario_banco').count().orderBy(col('count').desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|ano_mes|destinatario_banco|count|\n",
      "+-------+------------------+-----+\n",
      "|2023-01|              Itau|  267|\n",
      "|2023-01|             Caixa|  277|\n",
      "|2023-01|                XP|  277|\n",
      "|2023-01|          Bradesco|  280|\n",
      "|2023-01|            Nubank|  290|\n",
      "|2023-01|                C6|  290|\n",
      "|2023-01|               BTG|  278|\n",
      "|2022-12|                XP|  615|\n",
      "|2022-12|               BTG|  603|\n",
      "|2022-12|                C6|  576|\n",
      "|2022-12|          Bradesco|  575|\n",
      "|2022-12|            Nubank|  602|\n",
      "|2022-12|              Itau|  633|\n",
      "|2022-12|             Caixa|  616|\n",
      "|2022-11|          Bradesco|  579|\n",
      "|2022-11|               BTG|  580|\n",
      "|2022-11|              Itau|  614|\n",
      "|2022-11|            Nubank|  620|\n",
      "|2022-11|             Caixa|  543|\n",
      "|2022-11|                C6|  561|\n",
      "+-------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Quantas transações são realizadas por mês para cada banco?\n",
    "df_flatten.groupBy(\n",
    "    date_format('transaction_date', 'yyyy-MM').alias('ano_mes'), 'destinatario_banco'\n",
    "    ).count().orderBy(col('ano_mes').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "|destinatario_banco|avg(valor)|\n",
      "+------------------+----------+\n",
      "|          Bradesco| 10,564.19|\n",
      "|                XP| 10,328.07|\n",
      "|            Nubank| 10,316.48|\n",
      "|                C6| 10,309.50|\n",
      "|             Caixa| 10,254.86|\n",
      "|              Itau| 10,230.88|\n",
      "|               BTG| 10,122.30|\n",
      "+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valor de transação médio para cada banco\n",
    "#df_flatten.groupBy('destinatario_banco').avg('valor').orderBy(col('avg(valor)').asc()).show()\n",
    "average_df = df_flatten.groupBy('destinatario_banco').avg('valor')\n",
    "formatted_average_df = average_df.withColumn('avg(valor)', format_number(col('avg(valor)'), 2))\n",
    "formatted_average_df.orderBy(col('avg(valor)').desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+\n",
      "|destinatario_banco|    sum(valor)|\n",
      "+------------------+--------------+\n",
      "|          Bradesco|149,874,228.63|\n",
      "|                XP|148,734,558.71|\n",
      "|            Nubank|147,494,648.81|\n",
      "|                C6|146,436,134.80|\n",
      "|              Itau|146,107,144.52|\n",
      "|             Caixa|146,029,263.58|\n",
      "|               BTG|145,659,894.17|\n",
      "+------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Valor de transação total para cada banco\n",
    "sum_df = df_flatten.groupBy('destinatario_banco').sum('valor')\n",
    "formatted_sum_df = sum_df.withColumn('sum(valor)', format_number(col('sum(valor)'), 2))\n",
    "formatted_sum_df.orderBy(col('sum(valor)').desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----+\n",
      "|ano_mes|destinatario_banco|    categoria|count|\n",
      "+-------+------------------+-------------+-----+\n",
      "|2023-01|            Nubank|     educacao|   21|\n",
      "|2023-01|               BTG|    presentes|   22|\n",
      "|2023-01|              Itau|       outros|   27|\n",
      "|2023-01|                XP|   transporte|   32|\n",
      "|2023-01|               BTG|     educacao|   37|\n",
      "|2023-01|            Nubank|        lazer|   29|\n",
      "|2023-01|             Caixa|     educacao|   26|\n",
      "|2023-01|             Caixa|        lazer|   21|\n",
      "|2023-01|               BTG|        saude|   28|\n",
      "|2023-01|                XP|        lazer|   26|\n",
      "|2023-01|              Itau|     educacao|   30|\n",
      "|2023-01|             Caixa|    presentes|   31|\n",
      "|2023-01|            Nubank|    presentes|   25|\n",
      "|2023-01|             Caixa|  alimentacao|   31|\n",
      "|2023-01|                C6|  alimentacao|   30|\n",
      "|2023-01|            Nubank|        saude|   34|\n",
      "|2023-01|            Nubank|       outros|   35|\n",
      "|2023-01|            Nubank|   transporte|   28|\n",
      "|2023-01|                C6|transferencia|   63|\n",
      "|2023-01|          Bradesco|       outros|   22|\n",
      "+-------+------------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# total de transações por mês/banco por categoria\n",
    "df_flatten.groupBy(\n",
    "    date_format('transaction_date', 'yyyy-MM').alias('ano_mes'), 'destinatario_banco', 'categoria'\n",
    "    ).count().orderBy(col('ano_mes').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+-----+\n",
      "|destinatario_banco|    categoria|count|\n",
      "+------------------+-------------+-----+\n",
      "|               BTG|    vestuario| 1384|\n",
      "|                XP|    vestuario| 1351|\n",
      "|              Itau|    vestuario| 1373|\n",
      "|            Nubank|    vestuario| 1324|\n",
      "|                C6|    vestuario| 1357|\n",
      "|             Caixa|    vestuario| 1389|\n",
      "|          Bradesco|    vestuario| 1325|\n",
      "|            Nubank|   transporte| 1358|\n",
      "|             Caixa|   transporte| 1306|\n",
      "|               BTG|   transporte| 1357|\n",
      "|              Itau|   transporte| 1313|\n",
      "|                XP|   transporte| 1235|\n",
      "|          Bradesco|   transporte| 1292|\n",
      "|                C6|   transporte| 1313|\n",
      "|          Bradesco|transferencia| 3593|\n",
      "|              Itau|transferencia| 3533|\n",
      "|             Caixa|transferencia| 3525|\n",
      "|               BTG|transferencia| 3492|\n",
      "|                XP|transferencia| 3557|\n",
      "|                C6|transferencia| 3511|\n",
      "+------------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# total de transações por banco/categoria\n",
    "df_flatten.groupBy('destinatario_banco', 'categoria'\n",
    "    ).count().orderBy(col('categoria').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+\n",
      "| ano|    categoria|count|\n",
      "+----+-------------+-----+\n",
      "|2023|        saude|  193|\n",
      "|2023|    vestuario|  174|\n",
      "|2023|     educacao|  202|\n",
      "|2023|    presentes|  163|\n",
      "|2023|   transporte|  178|\n",
      "|2023|  alimentacao|  189|\n",
      "|2023|        lazer|  193|\n",
      "|2023|transferencia|  475|\n",
      "|2023|       outros|  192|\n",
      "|2022|       outros| 4702|\n",
      "|2022|        saude| 4784|\n",
      "|2022|        lazer| 4784|\n",
      "|2022|  alimentacao| 4799|\n",
      "|2022|   transporte| 4593|\n",
      "|2022|transferencia|12269|\n",
      "|2022|    vestuario| 4731|\n",
      "|2022|     educacao| 4681|\n",
      "|2022|    presentes| 4687|\n",
      "|2021|  alimentacao| 4560|\n",
      "|2021|    presentes| 4404|\n",
      "+----+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total de transações por categoria/ano\n",
    "df_flatten.groupBy(\n",
    "    date_format('transaction_date', 'yyyy').alias('ano'), 'categoria'\n",
    "    ).count().orderBy(col('ano').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    categoria|count|\n",
      "+-------------+-----+\n",
      "|transferencia|24744|\n",
      "|  alimentacao| 9548|\n",
      "|    vestuario| 9503|\n",
      "|        saude| 9476|\n",
      "|        lazer| 9464|\n",
      "|     educacao| 9460|\n",
      "|       outros| 9377|\n",
      "|    presentes| 9254|\n",
      "|   transporte| 9174|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total de transações por categoria\n",
    "df_flatten.groupBy('categoria').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "| ano|qunt_transacoes|\n",
      "+----+---------------+\n",
      "|2023|           1959|\n",
      "|2022|          50030|\n",
      "|2021|          48011|\n",
      "+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de transações por ano\n",
    "df_flatten.groupBy(date_format(col(\"transaction_date\"), \"yyyy\").alias(\"ano\")).agg(\n",
    "    count(\"id_transacao\").alias(\"qunt_transacoes\")\n",
    ").orderBy(\"ano\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+\n",
      "| ano|total_valor_transacoes|\n",
      "+----+----------------------+\n",
      "|2023|         19,594,633.67|\n",
      "|2022|        513,575,644.77|\n",
      "|2021|        497,165,594.78|\n",
      "+----+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# valor total de transações por ano\n",
    "df_flatten.groupBy(date_format(col(\"transaction_date\"), \"yyyy\").alias(\"ano\")).sum(\n",
    "    \"valor\"\n",
    ").select(\"ano\", format_number(col(\"sum(valor)\"), 2).alias(\"total_valor_transacoes\")).orderBy(\n",
    "    \"ano\", ascending=False\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "| ano|media_transacoes|\n",
      "+----+----------------+\n",
      "|2023|       10,002.37|\n",
      "|2022|       10,265.35|\n",
      "|2021|       10,355.24|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# valor médio de transações por ano\n",
    "df_flatten.groupBy(date_format(col(\"transaction_date\"), \"yyyy\").alias(\"ano\")).avg(\n",
    "    \"valor\"\n",
    ").select(\"ano\", format_number(col(\"avg(valor)\"), 2).alias(\"media_transacoes\")).orderBy(\n",
    "    \"ano\", ascending=False\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|fraude|count|\n",
      "+------+-----+\n",
      "|     1|15367|\n",
      "|     0|84633|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de fraudes\n",
    "df_flatten.groupBy(col('fraude')).count().alias('quantidade').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transacao: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- chave_pix: string (nullable = true)\n",
      " |-- fraude: integer (nullable = true)\n",
      " |-- remetente_nome: string (nullable = true)\n",
      " |-- remetente_banco: string (nullable = true)\n",
      " |-- remetente_tipo: string (nullable = true)\n",
      " |-- destinatario_nome: string (nullable = true)\n",
      " |-- destinatario_banco: string (nullable = true)\n",
      " |-- destinatario_tipo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flatten.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|    remetente_nome| count|\n",
      "+------------------+------+\n",
      "|Jonathan Gonsalves|100000|\n",
      "+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de transações por remetente\n",
    "df_flatten.groupBy(col('remetente_nome')).count().alias('quantidade').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|chave_pix|count|\n",
      "+---------+-----+\n",
      "|aleatoria|24810|\n",
      "|  celular|24863|\n",
      "|    email|25213|\n",
      "|      cpf|25114|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de transações or tipo de chave pix\n",
    "df_flatten.groupBy(col('chave_pix')).count().alias('quantidade').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   destinatario_nome|count|\n",
      "+--------------------+-----+\n",
      "|      Thomas Cardoso|   24|\n",
      "|   Alexandre Cardoso|   22|\n",
      "|   Ana Julia Cardoso|   22|\n",
      "|     Ana Julia Gomes|   21|\n",
      "|   Ana Julia Rezende|   20|\n",
      "|    Stephany Cardoso|   20|\n",
      "|       Maite Cardoso|   20|\n",
      "|      Stella Cardoso|   20|\n",
      "|        Julia Castro|   20|\n",
      "|    Ana Julia Duarte|   20|\n",
      "|Luiz Fernando Car...|   20|\n",
      "| Maria Clara Cardoso|   19|\n",
      "|Maria Sophia Cardoso|   19|\n",
      "|     Julia Fernandes|   19|\n",
      "|        Julia Moraes|   19|\n",
      "|      Miguel Cardoso|   18|\n",
      "|       Maysa Cardoso|   18|\n",
      "|          Theo Nunes|   18|\n",
      "|       Julia Costela|   18|\n",
      "|      Bianca Cardoso|   18|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de transações por destinatário\n",
    "df_flatten.groupBy(col('destinatario_nome')).count().alias('quantidade').orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "| ano|fraudes_ocorridas|\n",
      "+----+-----------------+\n",
      "|2023|           284.00|\n",
      "|2022|         7,642.00|\n",
      "|2021|         7,441.00|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Quantidade de fraudes por ano\n",
    "df_flatten.filter(col(\"fraude\") == 1).groupBy(\n",
    "    date_format(col(\"transaction_date\"), \"yyyy\").alias(\"ano\")\n",
    ").count().select(\"ano\", format_number(col(\"count\"), 2).alias(\"fraudes_ocorridas\")).orderBy(\n",
    "    \"ano\", ascending=False\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=========>        (1 + 1) / 2][Stage 54:>                 (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|  ano|    total|\n",
      "+-----+---------+\n",
      "| 2023|   284.00|\n",
      "| 2022| 7,642.00|\n",
      "| 2021| 7,441.00|\n",
      "|Total|15,367.00|\n",
      "+-----+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#verificar o total de fraudes por ano e tirar a prova dos valores comparados ao método anteriror\n",
    "\n",
    "# Conta o número de fraudes por ano\n",
    "df_yearly = df_flatten.filter(col(\"fraude\") == 1).groupBy(\n",
    "    date_format(col(\"transaction_date\"), \"yyyy\").alias(\"ano\")\n",
    ").count().select(\n",
    "    \"ano\", format_number(col(\"count\"), 2).alias(\"total\")\n",
    ").orderBy(\n",
    "    \"ano\", ascending=False\n",
    ")\n",
    "\n",
    "# Conta o número total de fraudes\n",
    "df_total = df_flatten.filter(col(\"fraude\") == 1).select(\n",
    "    lit(\"Total\").alias(\"ano\"), format_number(count(\"*\"), 2).alias(\"total\")\n",
    ")\n",
    "\n",
    "# Adiciona a linha total ao DataFrame\n",
    "df_result = df_yearly.union(df_total)\n",
    "\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-----+\n",
      "|fraude|    categoria|count|\n",
      "+------+-------------+-----+\n",
      "|     1|transferencia|15367|\n",
      "|     0|   transporte| 9174|\n",
      "|     0|        saude| 9476|\n",
      "|     0|       outros| 9377|\n",
      "|     0|    vestuario| 9503|\n",
      "|     0|    presentes| 9254|\n",
      "|     0|  alimentacao| 9548|\n",
      "|     0|        lazer| 9464|\n",
      "|     0|     educacao| 9460|\n",
      "|     0|transferencia| 9377|\n",
      "+------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento por cateria e fraude\n",
    "df_flatten.groupBy('fraude', 'categoria').count().orderBy('fraude', ascending =False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|range|count|\n",
      "+-----+-----+\n",
      "|19000|    1|\n",
      "|20000|  242|\n",
      "|21000|  231|\n",
      "|22000|  227|\n",
      "|23000|  230|\n",
      "|24000|  195|\n",
      "|25000|  233|\n",
      "|26000|  227|\n",
      "|27000|  242|\n",
      "|28000|  222|\n",
      "|29000|  233|\n",
      "|30000|  207|\n",
      "|31000|  242|\n",
      "|32000|  192|\n",
      "|33000|  207|\n",
      "|34000|  203|\n",
      "|35000|  254|\n",
      "|36000|  253|\n",
      "|37000|  252|\n",
      "|38000|  221|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# faixa de valores em que ocorreram fraudes\n",
    "\n",
    "df_flatten.filter(col(\"fraude\") == 1).withColumn(\n",
    "    \"range\", floor(col(\"valor\") / 1000) * 1000\n",
    ").groupBy(\"range\").count().orderBy(\"range\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|faixa_max_fraude|faixa_min_fraude|\n",
      "+----------------+----------------+\n",
      "|          89,000|           19000|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Faixa máxima e mínima de valores que ocorreram fraudes\n",
    "df_flatten.filter(col(\"fraude\") == 1).withColumn(\n",
    "    \"range\", floor(col(\"valor\") / 1000) * 1000\n",
    ").select(\n",
    "    format_number(max(\"range\"), 0).alias('faixa_max_fraude'),\n",
    "    min('range').alias('faixa_min_fraude')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIVX81NQzsoZ"
   },
   "source": [
    "## 5 - Modelo de Predição de Fraudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_transacao',\n",
       " 'valor',\n",
       " 'categoria',\n",
       " 'transaction_date',\n",
       " 'chave_pix',\n",
       " 'fraude',\n",
       " 'remetente_nome',\n",
       " 'remetente_banco',\n",
       " 'remetente_tipo',\n",
       " 'destinatario_nome',\n",
       " 'destinatario_banco',\n",
       " 'destinatario_tipo']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flatten.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_transacao',\n",
       " 'valor',\n",
       " 'remetente',\n",
       " 'destinatario',\n",
       " 'categoria',\n",
       " 'transaction_date',\n",
       " 'chave_pix',\n",
       " 'fraude']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(\n",
    "    inputCols=[\n",
    "        \"destinatario_nome\", \n",
    "        \"destinatario_banco\",\n",
    "        \"destinatario_tipo\",\n",
    "        \"categoria\",\n",
    "        \"chave_pix\"\n",
    "    ], \n",
    "    outputCols=[\n",
    "        \"destinatario_nome_index\", \n",
    "        \"destinatario_banco_index\",\n",
    "        \"destinatario_tipo_index\",\n",
    "        \"categoria_index\",\n",
    "        \"chave_pix_index\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:23:46 WARN DAGScheduler: Broadcasting large task binary with size 1278.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+-----------------------+------------------------+-----------------------+---------------+---------------+\n",
      "|id_transacao|             valor|    categoria|   transaction_date|chave_pix|fraude|    remetente_nome|remetente_banco|remetente_tipo|   destinatario_nome|destinatario_banco|destinatario_tipo|destinatario_nome_index|destinatario_banco_index|destinatario_tipo_index|categoria_index|chave_pix_index|\n",
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+-----------------------+------------------------+-----------------------+---------------+---------------+\n",
      "|        1000|            588.08|       outros|2021-07-16 05:00:55|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|         Calebe Melo|             Caixa|               PF|                12045.0|                     4.0|                    1.0|            6.0|            3.0|\n",
      "|        1001|           80682.5|transferencia|2022-04-20 12:34:01|  celular|     1|Jonathan Gonsalves|            BTG|            PF|  Davi Lucas Pereira|             Caixa|               PJ|                  259.0|                     4.0|                    0.0|            0.0|            2.0|\n",
      "|        1002|             549.9|        lazer|2022-07-10 16:51:34|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|      Sabrina Castro|            Nubank|               PF|                  132.0|                     2.0|                    1.0|            4.0|            1.0|\n",
      "|        1003|             90.83|   transporte|2022-10-20 10:57:36|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|Francisco da Conc...|            Nubank|               PJ|                10475.0|                     2.0|                    0.0|            8.0|            3.0|\n",
      "|        1004|13272.619999999999|transferencia|2021-04-06 20:26:51|    email|     0|Jonathan Gonsalves|            BTG|            PF|   Isabelly Ferreira|               BTG|               PJ|                 4159.0|                     1.0|                    0.0|            0.0|            0.0|\n",
      "|        1005|           9347.58|        saude|2022-07-24 15:22:27|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|Srta. Maria da Cunha|              Itau|               PJ|                26853.0|                     3.0|                    0.0|            3.0|            3.0|\n",
      "|        1006|           7836.76|    presentes|2022-10-05 19:20:24|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|     Catarina Duarte|                C6|               PF|                 5578.0|                     5.0|                    1.0|            7.0|            1.0|\n",
      "|        1007|           3883.62|    vestuario|2021-04-24 17:36:34|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|       Vitor Correia|                XP|               PJ|                13528.0|                     0.0|                    0.0|            2.0|            1.0|\n",
      "|        1008|               4.0|        saude|2021-11-16 21:46:47|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|         Theo Novaes|                C6|               PJ|                 1141.0|                     5.0|                    0.0|            3.0|            3.0|\n",
      "|        1009|              24.3|transferencia|2021-07-26 02:08:49|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|     Isabel Caldeira|                XP|               PJ|                 8369.0|                     0.0|                    0.0|            0.0|            1.0|\n",
      "|        1010|           87555.3|transferencia|2022-03-14 15:34:45|aleatoria|     1|Jonathan Gonsalves|            BTG|            PF|Sr. Henrique Cardoso|            Nubank|               PF|                22115.0|                     2.0|                    1.0|            0.0|            3.0|\n",
      "|        1011|          21345.91|transferencia|2021-10-31 04:31:51|      cpf|     1|Jonathan Gonsalves|            BTG|            PF|   Felipe Cavalcanti|            Nubank|               PJ|                 5897.0|                     2.0|                    0.0|            0.0|            1.0|\n",
      "|        1012|          73605.85|transferencia|2021-04-30 19:19:56|  celular|     1|Jonathan Gonsalves|            BTG|            PF|     Dr. Davi da Luz|          Bradesco|               PJ|                12212.0|                     6.0|                    0.0|            0.0|            2.0|\n",
      "|        1013|             93.53|  alimentacao|2023-01-13 13:39:57|      cpf|     0|Jonathan Gonsalves|            BTG|            PF|    Stephany Cardoso|                C6|               PJ|                   10.0|                     5.0|                    0.0|            1.0|            1.0|\n",
      "|        1014|            564.11|    vestuario|2022-05-27 23:06:08|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|   Sra. Julia Araujo|              Itau|               PJ|                24413.0|                     3.0|                    0.0|            2.0|            3.0|\n",
      "|        1015|              3.59|        saude|2021-10-06 21:19:58|    email|     0|Jonathan Gonsalves|            BTG|            PF|     Carolina Farias|            Nubank|               PJ|                10121.0|                     2.0|                    0.0|            3.0|            0.0|\n",
      "|        1016|          19164.89|  alimentacao|2022-03-06 17:59:43|    email|     0|Jonathan Gonsalves|            BTG|            PF|   Isabelly da Costa|            Nubank|               PJ|                 6122.0|                     2.0|                    0.0|            1.0|            0.0|\n",
      "|        1017|             68.45|    vestuario|2022-04-01 18:17:40|aleatoria|     0|Jonathan Gonsalves|            BTG|            PF|Joao Miguel Silveira|                C6|               PJ|                 6214.0|                     5.0|                    0.0|            2.0|            3.0|\n",
      "|        1018|            941.25|    vestuario|2022-05-23 00:28:13|  celular|     0|Jonathan Gonsalves|            BTG|            PF|       Matheus Moura|                C6|               PF|                 1829.0|                     5.0|                    1.0|            2.0|            2.0|\n",
      "|        1019|27009.910000000003|transferencia|2021-08-04 23:22:37|    email|     1|Jonathan Gonsalves|            BTG|            PF| Gabrielly Goncalves|              Itau|               PJ|                 5973.0|                     3.0|                    0.0|            0.0|            0.0|\n",
      "+------------+------------------+-------------+-------------------+---------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+-----------------------+------------------------+-----------------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_index = indexer.fit(df_flatten).transform(df_flatten)\n",
    "df_index.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para filtros, podemos usar somente colunas numéricas e de data\n",
    "cols_para_filtrar = [\n",
    "  \"valor\",\n",
    "  \"transaction_date\",\n",
    "  \"destinatario_nome_index\", \n",
    "  \"destinatario_banco_index\",\n",
    "  \"destinatario_tipo_index\",\n",
    "  \"chave_pix_index\",\n",
    "  \"categoria_index\",\n",
    "  \"fraude\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fraud = df_index.select(cols_para_filtrar).filter(col(\"fraude\") == 1)\n",
    "not_fraud = df_index.select(cols_para_filtrar).filter(col(\"fraude\") == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar amostra dos dados de fraude\n",
    "not_fraud = not_fraud.sample(False, 0.1, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23712"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = not_fraud.union(is_fraud)\n",
    "df = df_concat.sort(\"transaction_date\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:23:48 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:23:50 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:23:52 WARN DAGScheduler: Broadcasting large task binary with size 1296.6 KiB\n",
      "24/05/28 01:23:52 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:23:54 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:23:56 WARN DAGScheduler: Broadcasting large task binary with size 1296.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 16504  test = 7208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 123)\n",
    "print(\"train =\", train.count(), \" test =\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fraud = udf(lambda fraud: 1.0 if fraud > 0 else 0.0, DoubleType())\n",
    "train = train.withColumn(\"is_fraud\", is_fraud(train.fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:23:56 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:23:58 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:00 WARN DAGScheduler: Broadcasting large task binary with size 2041.6 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train.write.mode(\"overwrite\").parquet(f\"data{os.sep}stage{os.sep}train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:24:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:24:02 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:04 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:06 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:07 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:09 WARN DAGScheduler: Broadcasting large task binary with size 1340.9 KiB\n",
      "24/05/28 01:24:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/28 01:24:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/05/28 01:24:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "24/05/28 01:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:17 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:19 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:20 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "[Stage 204:============================>                            (2 + 2) / 4]\r"
     ]
    }
   ],
   "source": [
    "# Create the feature vectors.\n",
    "assembler = VectorAssembler(\n",
    "  inputCols = [x for x in train.columns if x not in [\"transaction_date\", \"fraude\", \"is_fraud\"]],\n",
    "  outputCol = \"features\")\n",
    "\n",
    "# Use Logistic Regression.\n",
    "lr = LogisticRegression().setParams(\n",
    "    maxIter = 100000,\n",
    "    labelCol = \"is_fraud\",\n",
    "    predictionCol = \"prediction\")\n",
    "\n",
    "spark = spark.builder.config(\"spark.network.timeout\", \"600s\").getOrCreate()\n",
    "\n",
    "# Repartition the train DataFrame into 4 partitions\n",
    "# train = train.repartition()\n",
    "\n",
    "# This will train a logistic regression model on the input data and return a \n",
    "# LogisticRegressionModel object which can be used to make predictions on new data.\n",
    "model = Pipeline(stages = [assembler, lr]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:24:22 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:24 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:25 WARN DAGScheduler: Broadcasting large task binary with size 1339.8 KiB\n",
      "24/05/28 01:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1330.9 KiB\n",
      "24/05/28 01:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1330.6 KiB\n",
      "24/05/28 01:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1328.3 KiB\n",
      "24/05/28 01:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:28 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:30 WARN DAGScheduler: Broadcasting large task binary with size 1346.0 KiB\n",
      "24/05/28 01:24:30 WARN DAGScheduler: Broadcasting large task binary with size 1334.2 KiB\n",
      "24/05/28 01:24:31 WARN DAGScheduler: Broadcasting large task binary with size 1344.5 KiB\n",
      "24/05/28 01:24:32 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "24/05/28 01:24:33 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/05/28 01:24:35 WARN DAGScheduler: Broadcasting large task binary with size 1346.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+----+-----------+-----------+\n",
      "|is_fraud_prediction| 0_0| 1_0|0_0_percent|1_0_percent|\n",
      "+-------------------+----+----+-----------+-----------+\n",
      "|                1.0|   0|4636|        0.0|      64.31|\n",
      "|                0.0|2571|   1|      35.66|       0.01|\n",
      "+-------------------+----+----+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 01:24:35 WARN DAGScheduler: Broadcasting large task binary with size 1334.8 KiB\n",
      "24/05/28 01:24:35 WARN DAGScheduler: Broadcasting large task binary with size 1340.6 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Transforma os dados de teste usando o modelo\n",
    "predicted = model.transform(test)\n",
    "\n",
    "# Adiciona uma nova coluna 'is_fraud' ao DataFrame\n",
    "predicted = predicted.withColumn(\"is_fraud\", is_fraud(predicted.fraude))\n",
    "\n",
    "# Cria uma tabela de contingência (crosstab) entre 'is_fraud' e 'prediction'\n",
    "crosstab_df = predicted.crosstab(\"is_fraud\", \"prediction\")\n",
    "\n",
    "# Converte os nomes das colunas para strings\n",
    "crosstab_df = crosstab_df.toDF(*(c.replace('.', '_') for c in crosstab_df.columns))\n",
    "\n",
    "# Calcula a soma total de todas as linhas\n",
    "total = crosstab_df.select(*(col(c).cast(\"int\") for c in crosstab_df.columns)).rdd.flatMap(lambda x: x).reduce(lambda x, y: x + y)\n",
    "\n",
    "# Adiciona novas colunas ao DataFrame para mostrar as porcentagens\n",
    "for column in crosstab_df.columns[1:]:\n",
    "    crosstab_df = crosstab_df.withColumn(column + '_percent', round((col(column) / lit(total)) * 100, 2))\n",
    "\n",
    "crosstab_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zHoQJWtATfX"
   },
   "source": [
    "# Avaliação do Modelo\n",
    "Será que seu modelo atinge todas as necessidades que foram definidas inicialmente?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Normalização dos dados\n",
    "  - [x] O dataset será em  `*.json`. Analisar a estrutura do arquivo\n",
    "  - [x] Faça sua transformação para formato colunar\n",
    "- [x] Análise Exploratória de Dados: Use o PySpark para analisar padrões de uso do PIX\n",
    "  - [x] chaves pix mais usadas;\n",
    "  - [x] os valores de transação mais comuns;\n",
    "  - [x] distribuição dos valores de transação\n",
    "    - [x] hora\n",
    "    - [x] dia\n",
    "  - [x] quais bancos receberam mais transferências por dia;\n",
    "  - [x] para qual tipo de pessoa (PF ou PJ) foram realizadas mais transações\n",
    "- [x] Engenharia de Recursos: \n",
    "  - [x] Apresentar novas características que podem ser úteis para a detecção de fraudes, tais como o número de transações feitas pelo mesmo remetente em um período de tempo específico.\n",
    "- [x] Modelagem: Use o PySpark MLlib para treinar e detectar possíveis transações que contenham fraude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOTAB1JSAVPi"
   },
   "source": [
    "# Deployment\n",
    "Apresente o relatório com os resultados obtidos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
